{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5aJi6tTQ96e"
      },
      "source": [
        "# Info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxIK7042Q96j"
      },
      "source": [
        "[<img align=\"right\" width=\"400\" height=\"400\" src=\"https://github.com/ML-IGP-TUBS-2025/Julian-Thoms/blob/master/Assignments/Assignment08-Decison%20trees/assets/TUBS_IGP_logo.jpg?raw=1\">](https://www.tu-braunschweig.de/en/igp)\n",
        "\n",
        "[Mehdi Maboudi](https://www.tu-braunschweig.de/en/igp/staff/mehdi-maboudi) ([m.maboudi@tu-bs.de](m.maboudi@tu-bs.de))\n",
        "\n",
        "[Technical University of Braunschweig](https://www.tu-braunschweig.de/en/)  \n",
        "[Institute of Geodesy and Photogrammetry](https://www.tu-braunschweig.de/igp)  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4J2sWseQ96l"
      },
      "source": [
        "**Decision Tree exercise**  \n",
        "Complete and hand in this worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission.\n",
        "***\n",
        "In this exercise you will:\n",
        "- implement a CART-like Decision Tree on [**Iris dataset**](https://en.wikipedia.org/wiki/Iris_flower_data_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kl9dykeZQ96n"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "-1zNFpefQ96o",
        "outputId": "b078507c-b395-4e2c-dd5d-020eddd4881e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'imp'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1639436778.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Some more magic so that the notebook will reload external python modules;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-57>\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/extension.py\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Missing module name.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'already loaded'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/extensions.py\u001b[0m in \u001b[0;36mload_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule_str\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprepended_to_syspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                         print((\"Loading extensions from {dir} is deprecated. \"\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/extensions/autoreload.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msource_from_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m#------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imp'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Some more magic so that the notebook will reload external python modules;\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "#ganzes Assignment auf google drive hochladen\n",
        "#from importlib import reload #unsupported by python 3.12\n",
        "\n",
        "seed = 57"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Sskl6hyEQ96p"
      },
      "outputs": [],
      "source": [
        "# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
        "try:\n",
        "    del X_train, y_train\n",
        "    del X_test, y_test\n",
        "    print(\"Clear previously loaded data.\")\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK-hzRmMQ96q"
      },
      "source": [
        "# Iris dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRDvN5b4Q96q"
      },
      "source": [
        "In this assignment you are asked to separate 3 classes of Iris dataset.  \n",
        "We will use just using petal length and petal width."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YhbxZquTQ96s"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "\n",
        "def Import_Iris_data():\n",
        "    iris = load_iris()\n",
        "    X = iris.data[:, 2:]  # petal length and width\n",
        "    y = iris.target\n",
        "    Classes = np.unique(y)\n",
        "\n",
        "    return X, y, Classes\n",
        "\n",
        "\n",
        "X, y, Classes = Import_Iris_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ffz6vJSQ96t"
      },
      "source": [
        "## visualize dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bcASkiSdQ96u"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "\n",
        "def plot_samples_classification(X, y,clf=None,figsize=(8, 4)):\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.plot(X[:, 0][y == 0], X[:, 1][y == 0], \"yo\", label=\"Iris setosa\")\n",
        "    plt.plot(X[:, 0][y == 1], X[:, 1][y == 1], \"bs\", label=\"Iris versicolor\")\n",
        "    plt.plot(X[:, 0][y == 2], X[:, 1][y == 2], \"g^\", label=\"Iris virginica\")\n",
        "\n",
        "    view_scale = 0.05\n",
        "    x1min, x1max = np.min(X[:, 0]), np.max(X[:, 0])\n",
        "    x1min -= view_scale * (x1max - x1min)\n",
        "    x1max += view_scale * (x1max - x1min)\n",
        "\n",
        "    x2min, x2max = np.min(X[:, 1]), np.max(X[:, 1])\n",
        "    x2min -= view_scale * (x2max - x2min)\n",
        "    x2max += view_scale * (x2max - x2min)\n",
        "    plt.xlabel(r\"$x_1$\", fontsize=18)\n",
        "    plt.ylabel(r\"$x_2$\", fontsize=18)\n",
        "\n",
        "\n",
        "    if clf: #there is a classifier\n",
        "        x1s = np.linspace(x1min, x1max, 100)\n",
        "        x2s = np.linspace(x2min, x2max, 100)\n",
        "        x1, x2 = np.meshgrid(x1s, x2s)\n",
        "        X_new = np.c_[x1.ravel(), x2.ravel()]\n",
        "        y_pred = clf.predict(X_new).reshape(x1.shape)\n",
        "        custom_cmap = ListedColormap([\"#fafab0\", \"#9898ff\", \"#a0faa0\"])\n",
        "        plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n",
        "        plt.title(f\"decision boundaries of Decision Tree\")\n",
        "\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "9uUai46oQ96v",
        "outputId": "3b2e2e28-48b0-400e-87ec-6daef62aa476"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_samples_classification(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtluWXfJQ96w"
      },
      "source": [
        "# Decision Tree Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhDqxp9yQ96w"
      },
      "source": [
        "## Finding all the candidates for splitting the current node (20pnts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq2b3vQAQ96w"
      },
      "source": [
        "First, open `TUBS_1120019/decision_tree_classifier/split.py` and implement the function *find_Candidates_for_Splitting_thisFeature* that computes the possible candidates for splitting a feature. Then run the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYNO6IoTQ96x",
        "outputId": "33c41310-4745-42ad-e753-42255ac17d3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "split candidates:\n",
            "feature0 candidates:[np.float64(2.45), np.float64(4.5), np.float64(4.5), np.float64(4.8), np.float64(4.85), np.float64(4.9), np.float64(4.9), np.float64(4.95), np.float64(5.0), np.float64(5.05), np.float64(5.1), np.float64(5.1)]\n",
            "feature1 candidates:[np.float64(0.8), np.float64(1.4), np.float64(1.45), np.float64(1.5), np.float64(1.5), np.float64(1.5), np.float64(1.5), np.float64(1.6), np.float64(1.7), np.float64(1.75), np.float64(1.8), np.float64(1.8)]\n"
          ]
        }
      ],
      "source": [
        "#from TUBS_1120019.decision_tree_classifier.split import find_Candidates_for_Splitting_thisFeature\n",
        "#direkt hier her importiert\n",
        "\n",
        "def find_Candidates_for_Splitting_thisFeature(This_Feature,labels):\n",
        "    \"\"\"\n",
        "    An iterative approach for all samples:\n",
        "    If label of a sample is different from its next neighbour's,\n",
        "    their mean on This_feature will be considered as candidates for splitting \"This_Feature\".\n",
        "\n",
        "\n",
        "    Inputs:\n",
        "        - This_Feature: A numpy array of shape (N,) containing the \"This_Feature\" values of all samples in the current node\n",
        "        --> eine Spalte , die die X-Werte für unser ausgewähltes Feature beinhaltet\n",
        "        - y: A numpy array of shape (N,) containing the labels of all samples in the current node, where\n",
        "             y[i] is the label for This_Feature[i].\n",
        "\n",
        "    Outputs:\n",
        "        - split_candidates: A list containing all candidates for splitting the current feature\n",
        "    \"\"\"\n",
        "\n",
        "    split_candidates=[]\n",
        "\n",
        "   #####################################################################\n",
        "   # TODO:                                                             #\n",
        "   # Compute the candidates for splitting This_Feature.                #\n",
        "   # You should first sort the samples based on This_Feature values    #\n",
        "   # Then considering all feature values which                         #\n",
        "   # correspond to the class change as a candidate.                    #\n",
        "   # Final split_candidates are a set constaining the mean between     #\n",
        "   # each candidate and next feature value of This_Feature.            #\n",
        "   #####################################################################\n",
        "   # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    #Features sortieren\n",
        "    #argsort sortiert nur die Indizes, nicht die Werte des Arrays\n",
        "    # andere Möglichkeit: beide Spalten zusammenfügen: data=np., dann sortieren\n",
        "    sorted_values=np.argsort(This_Feature)\n",
        "    sorted_This_Feature=This_Feature[sorted_values]\n",
        "    sorted_labels=labels[sorted_values]\n",
        "\n",
        "    #class change\n",
        "    for i in range(len(sorted_values)-1):\n",
        "      if sorted_labels[i]!=sorted_labels[i+1]:\n",
        "        #Mittelwert wird als Wert zum splitten von This_feature genutzt\n",
        "        candidate=(sorted_This_Feature[i]+sorted_This_Feature[i+1])/2\n",
        "        split_candidates.append(candidate)\n",
        "\n",
        "   # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "\n",
        "    return split_candidates\n",
        "\n",
        "candidates = []\n",
        "print(\"split candidates:\")\n",
        "for feature in range(X.shape[1]):\n",
        "    candidates_this_feature = find_Candidates_for_Splitting_thisFeature (X[:,feature],y)\n",
        "\n",
        "    print(f\"feature{feature} candidates:{candidates_this_feature}\")\n",
        "    candidates.append([candidates_this_feature])"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "YnTbrwZQQ96x"
      },
      "source": [
        "Your result should look like:\n",
        "\n",
        "split candidates:\n",
        "feature0 candidates:[1.8  2.45 3.65 4.35 4.45 4.55 4.65 4.75 4.85 4.95 5.05 5.15]\n",
        "feature1 candidates:[0.55 0.8  1.1  1.25 1.35 1.45 1.55 1.65 1.75 1.85]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5hMtV6hQ96y"
      },
      "source": [
        "## Impurity measures (6 pnts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7QZ215vQ96y"
      },
      "source": [
        "open `TUBS_1120019/decision_tree_classifier/Impurity.py` and implement the functions *Entropy* and *Gini* and run the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMs3ha87Q96y",
        "outputId": "d6c72b99-26c7-4f54-f1de-4322fa9f464e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "impurity_criterion Entropy = 1.584962500721156\n",
            "impurity_criterion Gini= 2.6666666666666665\n"
          ]
        }
      ],
      "source": [
        "#from TUBS_1120019.decision_tree_classifier.Impurity import Compute_Impurity\n",
        "\n",
        "def Entropy(p):\n",
        "    \"\"\"\n",
        "    Compute the entropy index using the given probabilities\n",
        "\n",
        "    Inputs:\n",
        "    - p: A numpy array of shape (K, 1) containing probilities of all K classes in the dataset\n",
        "\n",
        "    Returns:\n",
        "    - entropy_: float: entropy of the samples in the node\n",
        "    \"\"\"\n",
        "    entropy_ = 0.0\n",
        "    #####################################################################\n",
        "    # TODO:                                                             #\n",
        "    # Compute the entropy index using the given probabilities           #\n",
        "    #####################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    for element in p:\n",
        "      entropy_+=(-element*np.log2(element))\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    return entropy_\n",
        "\n",
        "\n",
        "def Gini(p):\n",
        "    \"\"\"\n",
        "    Compute the Gini index using the given probabilities\n",
        "\n",
        "    Inputs:\n",
        "    - p: A numpy array of shape (K, 1) containing probilities of all K classes in the dataset\n",
        "\n",
        "    Returns:\n",
        "    - gini_: float: gini index of the samples in the node\n",
        "    \"\"\"\n",
        "    gini_ = 0.0\n",
        "    #####################################################################\n",
        "    # TODO:                                                             #\n",
        "    # Compute the Gini index using the given probabilities              #\n",
        "    #####################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    for element in p:\n",
        "      gini_+=(1-element**2)\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    return gini_\n",
        "\n",
        "\n",
        "def Compute_Impurity(y,Classes,criterion='gini'):\n",
        "    \"\"\"\n",
        "    Compute the impurity of the labels using the given Classes and criterion\n",
        "\n",
        "    Inputs:\n",
        "    - y: A numpy array of shape (n, ) containing labels\n",
        "    - Classes: Numpy array of size (K,) containing the labels of classes in the dataset\n",
        "    - criterion: string:  impurity index\n",
        "\n",
        "    Returns:\n",
        "    - : float: impurity index of the labels\n",
        "    \"\"\"\n",
        "    count=[0.]*len(Classes)\n",
        "    for c in Classes:\n",
        "        count[c]=np.count_nonzero(y==c)\n",
        "    p=count/np.sum(count)\n",
        "\n",
        "    if   criterion.lower() == 'gini':\n",
        "        return Gini(p)\n",
        "    elif criterion.lower() == 'entropy':\n",
        "        return Entropy(p)\n",
        "    else:\n",
        "        raise NameError(\"Impurity criterion must be gini or entropy\")\n",
        "\n",
        "\n",
        "\n",
        "impurity_criterion='entropy'\n",
        "node_impurity = Compute_Impurity(y,Classes,criterion=impurity_criterion)\n",
        "print(\"impurity_criterion Entropy =\", node_impurity)\n",
        "\n",
        "\n",
        "impurity_criterion='gini'\n",
        "node_impurity = Compute_Impurity(y,Classes,criterion=impurity_criterion)\n",
        "print(\"impurity_criterion Gini=\", node_impurity)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "rxDDDBDhQ96y"
      },
      "source": [
        "Your result should look like:\n",
        "\n",
        "entropy = 1.5850\n",
        "gini = 0.6667"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4wlFAkxQ96z"
      },
      "source": [
        "## Selecting the best candidate for splitting the current node"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMG3j4etQ96z"
      },
      "source": [
        "### Evaluate each binary split (15 pnts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Wtdl-3DQ96z"
      },
      "source": [
        "In `TUBS_1120019/decision_tree_classifier/split.py` implement the function *evaluate_binary_split* to compute the overall impurity of the child nodes after a binary split. Then run the code below:  \n",
        "splitting candidate which results to minimum overall impurity of the child nodes would be the best choice for this node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wU592RLQ960",
        "outputId": "03748620-3646-4116-e044-23bf77dc90d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature: 0, splitting candidate:2.4500, overall_impurity_child_nodes: nan\n",
            "feature: 0, splitting candidate:4.5000, overall_impurity_child_nodes: nan\n",
            "feature: 0, splitting candidate:4.5000, overall_impurity_child_nodes: nan\n",
            "feature: 0, splitting candidate:4.8000, overall_impurity_child_nodes: nan\n",
            "feature: 0, splitting candidate:4.8500, overall_impurity_child_nodes: nan\n",
            "feature: 0, splitting candidate:4.9000, overall_impurity_child_nodes: nan\n",
            "feature: 0, splitting candidate:4.9000, overall_impurity_child_nodes: nan\n",
            "feature: 0, splitting candidate:4.9500, overall_impurity_child_nodes: nan\n",
            "feature: 0, splitting candidate:5.0000, overall_impurity_child_nodes: nan\n",
            "feature: 0, splitting candidate:5.0500, overall_impurity_child_nodes: nan\n",
            "feature: 0, splitting candidate:5.1000, overall_impurity_child_nodes: nan\n",
            "feature: 0, splitting candidate:5.1000, overall_impurity_child_nodes: nan\n",
            "feature: 1, splitting candidate:0.8000, overall_impurity_child_nodes: nan\n",
            "feature: 1, splitting candidate:1.4000, overall_impurity_child_nodes: nan\n",
            "feature: 1, splitting candidate:1.4500, overall_impurity_child_nodes: nan\n",
            "feature: 1, splitting candidate:1.5000, overall_impurity_child_nodes: nan\n",
            "feature: 1, splitting candidate:1.5000, overall_impurity_child_nodes: nan\n",
            "feature: 1, splitting candidate:1.5000, overall_impurity_child_nodes: nan\n",
            "feature: 1, splitting candidate:1.5000, overall_impurity_child_nodes: nan\n",
            "feature: 1, splitting candidate:1.6000, overall_impurity_child_nodes: nan\n",
            "feature: 1, splitting candidate:1.7000, overall_impurity_child_nodes: nan\n",
            "feature: 1, splitting candidate:1.7500, overall_impurity_child_nodes: nan\n",
            "feature: 1, splitting candidate:1.8000, overall_impurity_child_nodes: nan\n",
            "feature: 1, splitting candidate:1.8000, overall_impurity_child_nodes: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3940156076.py:21: RuntimeWarning: divide by zero encountered in log2\n",
            "  entropy_+=(-element*np.log2(element))\n",
            "/tmp/ipython-input-3940156076.py:21: RuntimeWarning: invalid value encountered in scalar multiply\n",
            "  entropy_+=(-element*np.log2(element))\n"
          ]
        }
      ],
      "source": [
        "#from TUBS_1120019.decision_tree_classifier.split import evaluate_binary_split\n",
        "\n",
        "#from .Impurity import Compute_Impurity\n",
        "def evaluate_binary_split(feature,labels,Classes,Threshold,criterion='gini'):\n",
        "    \"\"\"\n",
        "    evaluates a Binary split of the samples (given their one feature and labels)\n",
        "    Note: Split is binary, but it could manage multi-class dataset\n",
        "\n",
        "\n",
        "    Inputs:\n",
        "        - feature: A numpy array of shape (N,) containing the this feature values of all samples in the current node\n",
        "        - labels: A numpy array of shape (N,) containing the labels of all samples in the current node, where\n",
        "             y[i] is the label for feature[i].\n",
        "        - Classes: list of integers contating K integers as Class labels\n",
        "        - Threshold: Threshold (on feature) for dividing the samples into two sets\n",
        "          (feature values equal or less than the threshold as one set and\n",
        "           feature values greater than the threshold as another sample)\n",
        "\n",
        "    Outputs:\n",
        "        - overall_impurity_child_nodes: float:\n",
        "          contains weighted sum of impurities of set1 and set2 (in a binary split by applying Threshold on feature)\n",
        "             overall_impurity_child_nodes = N1/N*I1+N2/N*I2\n",
        "                where N is: number of samples in the parent node, and\n",
        "                N1 and N2: number of samples in set1 and set2\n",
        "                I1 and I2: Impurity of set1 and set2, accordingly\n",
        "\n",
        "    \"\"\"\n",
        "    overall_impurity_child_nodes = None\n",
        "   #####################################################################\n",
        "   # TODO:                                                             #\n",
        "   # Compute overall_impurity_after_binary_split                       #\n",
        "   # The output is a nice measure for deciding about                   #\n",
        "   # the best featur for and best value for splitting the samples      #\n",
        "   # You should first use threshold to make two sets from the samples  #\n",
        "   # Then compute the impurity of each set                             #\n",
        "   # Finally, compute the overall_impurity_after_binary_split          #\n",
        "   #####################################################################\n",
        "   # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    #Threshold ist der Wert, an dem wir die features splitten(vorher haben wir mögliche split_candidates berechnet)\n",
        "    #Hier: labels werden gesplittet\n",
        "    set1_labels=labels[feature<=Threshold]\n",
        "    set2_labels=labels[feature>Threshold]\n",
        "\n",
        "    I1=Compute_Impurity(set1_labels,Classes,criterion)\n",
        "    I2=Compute_Impurity(set2_labels,Classes,criterion)\n",
        "\n",
        "    overall_impurity_child_nodes=(len(set1_labels)/len(labels))*I1+(len(set2_labels)/len(labels))*I2\n",
        "\n",
        "\n",
        "    #feature 0 und 1 für petal_width und petal_length\n",
        "    #die beiden Stellen mit nan lassen volle Reinheit beim split zu (die eine Irissorte ist isoliert, die anderen dichter zusammen)\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    return overall_impurity_child_nodes\n",
        "\n",
        "#bis hier importiert\n",
        "for feature in range(len(candidates)):\n",
        "    for c in candidates[feature][0]:\n",
        "        overall_impurity_after_split = evaluate_binary_split(\n",
        "            X[:, feature], y, Classes, Threshold=c, criterion=\"entropy\")\n",
        "\n",
        "        print(f\"feature: {feature}, splitting candidate:{c:.4f}, overall_impurity_child_nodes: {overall_impurity_after_split:.6f}\")"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "_ty1ZOUlQ960"
      },
      "source": [
        "Your result should look like:\n",
        "\n",
        "\n",
        "feature: 0, splitting candidate:1.8000, overall_impurity_child_nodes: 0.761345\n",
        "feature: 0, splitting candidate:2.4500, overall_impurity_child_nodes: 0.666667\n",
        "feature: 0, splitting candidate:3.6500, overall_impurity_child_nodes: 0.808219\n",
        "feature: 0, splitting candidate:4.3500, overall_impurity_child_nodes: 0.918296\n",
        "feature: 0, splitting candidate:4.4500, overall_impurity_child_nodes: 0.914167\n",
        "feature: 0, splitting candidate:4.5500, overall_impurity_child_nodes: 0.935806\n",
        "feature: 0, splitting candidate:4.6500, overall_impurity_child_nodes: 0.914548\n",
        "feature: 0, splitting candidate:4.7500, overall_impurity_child_nodes: 0.860485\n",
        "feature: 0, splitting candidate:4.8500, overall_impurity_child_nodes: 0.903352\n",
        "feature: 0, splitting candidate:4.9500, overall_impurity_child_nodes: 0.952892\n",
        "feature: 0, splitting candidate:5.0500, overall_impurity_child_nodes: 1.003351\n",
        "feature: 0, splitting candidate:5.1500, overall_impurity_child_nodes: 1.114268\n",
        "feature: 1, splitting candidate:0.5500, overall_impurity_child_nodes: 0.720625\n",
        "feature: 1, splitting candidate:0.8000, overall_impurity_child_nodes: 0.666667\n",
        "feature: 1, splitting candidate:1.1000, overall_impurity_child_nodes: 0.854655\n",
        "feature: 1, splitting candidate:1.2500, overall_impurity_child_nodes: 0.891588\n",
        "feature: 1, splitting candidate:1.3500, overall_impurity_child_nodes: 0.915979\n",
        "feature: 1, splitting candidate:1.4500, overall_impurity_child_nodes: 0.941446\n",
        "feature: 1, splitting candidate:1.5500, overall_impurity_child_nodes: 0.919387\n",
        "feature: 1, splitting candidate:1.6500, overall_impurity_child_nodes: 0.895405\n",
        "feature: 1, splitting candidate:1.7500, overall_impurity_child_nodes: 0.899153\n",
        "feature: 1, splitting candidate:1.8500, overall_impurity_child_nodes: 1.114268"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uPcQR2IQ961"
      },
      "source": [
        "### greedy selection of the best split (10 pnts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_yg_j24Q961"
      },
      "source": [
        "Now, you are ready to find the best split (feature and threshold) for splitting a binary node.\n",
        "open `TUBS_1120019/decision_tree_classifier/Node.py` and implement the function *__find_best_split* for greedy selection of the best split of a binary node. Then run the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJhHjCwVQ961",
        "outputId": "b7b3d656-4601-4173-b935-56e7c86d356f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------\n",
            "Describing Node[0]:\n",
            "depth =0, ID = [0]\n",
            "leaf?: True\n",
            "samples = 150, counts = [50. 50. 50.], proabilities = [0.33333333 0.33333333 0.33333333]\n",
            "impurity: entropy = 1.585\n",
            "Class: 0\n"
          ]
        }
      ],
      "source": [
        "#from TUBS_1120019.decision_tree_classifier.Node import BinaryNode\n",
        "\n",
        "#ab hier importiert\n",
        "class BinaryNode:\n",
        "  # This class is defined for Binary Decision Trees\n",
        "\n",
        "    def __init__(self,samples,labels,Classes,\n",
        "                 Impurity_criterion = 'gini',\n",
        "                 parentID=None,Branch = True):\n",
        "\n",
        "        self.__check_inputs(samples,labels)\n",
        "        self.__assign_ID(parentID, Branch)\n",
        "        self.depth = len(self.ID)-1\n",
        "        self.num_samples =  self.samples.shape[0]\n",
        "        self.__count_samples_per_class(Classes)\n",
        "        self.probs=self.count/np.sum(self.count)\n",
        "        self.impurity_criterion = Impurity_criterion.lower()\n",
        "        self.__compute_impurity()\n",
        "        self.Classes = Classes\n",
        "        self.Class = np.argmax(self.count) #majority voting\n",
        "        if self.impurity==0:\n",
        "            self.splittable = False\n",
        "            self.splitting_feature__ = None\n",
        "            self.splitting_feature_Threshold__ = None\n",
        "        else:\n",
        "            self.splittable = True\n",
        "            self.set_splitting_feature_and_threshold()\n",
        "\n",
        "\n",
        "    def __check_inputs(self,samples,labels):\n",
        "        if samples.shape[0]==len(labels):\n",
        "            self.samples = samples\n",
        "            self.labels  = labels\n",
        "        else:\n",
        "            raise NameError(\"Check Input data\")\n",
        "\n",
        "    def __assign_ID(self,parentID,Branch):\n",
        "        if parentID is None:#Root Node\n",
        "            self.ID=[0]\n",
        "        elif Branch == True:\n",
        "            self.ID = parentID+[1]\n",
        "        else:\n",
        "            self.ID = parentID+[0]\n",
        "\n",
        "\n",
        "    def __compute_impurity(self):\n",
        "        \"\"\"\n",
        "        A method for computing the impurity of the samples in the Node(self)\n",
        "        \"\"\"\n",
        "        if self.impurity_criterion == 'gini':\n",
        "            self.impurity = Gini(self.probs)\n",
        "        elif self.impurity_criterion == 'entropy':\n",
        "            self.impurity = Entropy(self.probs)\n",
        "        else:\n",
        "            raise NameError(\"Undefined impurity criterion.\")\n",
        "\n",
        "\n",
        "    def set_splitting_feature_and_threshold(self,splitting_feature='None',splitting_feature_Threshold='None'):\n",
        "        if (splitting_feature != 'None') and (splitting_feature_Threshold != 'None'):\n",
        "            self.splitting_feature__ = splitting_feature\n",
        "            self.splitting_feature_Threshold__ = splitting_feature_Threshold\n",
        "        else:\n",
        "            self.__find_best_split()\n",
        "\n",
        "\n",
        "    def __find_best_split(self):\n",
        "        \"\"\"\n",
        "        Compute the best split of the Node.\n",
        "        splitting_feature__ and splitting_feature_Threshold__ should be computed based on overall impurity after split\n",
        "\n",
        "        Inputs:\n",
        "        - self: Node\n",
        "\n",
        "        Returns:\n",
        "        - sets the following attributes of \"self\"(object):\n",
        "             .splitting_feature__: int: selected feature for aplitting the samples of this Node\n",
        "             .splitting_feature_Threshold__: float: splitting threshold of the selected feature (splitting_feature__)\n",
        "             .splittable = True or False\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        num_features = self.samples.shape[1]\n",
        "        best_feature = None\n",
        "        best_split_value=None\n",
        "        best_impurity = self.impurity\n",
        "\n",
        "        for feature in range(num_features):\n",
        "            #####################################################################\n",
        "            # TODO:                                                             #\n",
        "            # Compute the candidates for splitting the samples using feature:   #\n",
        "            # use find_Candidates_for_Splitting_thisFeature in \"split.py\"       #\n",
        "            #####################################################################\n",
        "            # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "            split_features: int=None\n",
        "            split_feature=find_Candidates_for_Splitting_thisFeature(feature,)\n",
        "\n",
        "\n",
        "            # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "\n",
        "            #####################################################################\n",
        "            # TODO:                                                             #\n",
        "            # use evaluate_binary_split function in \"split.py\" in a for loop to #\n",
        "            # evaluate each candidate of current feature to                     #\n",
        "            # update 2 parameters best_feature, and best_split_value            #\n",
        "            #####################################################################\n",
        "            # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    N=len(labels)\n",
        "    N1=len(set1_labels)\n",
        "    N2=len(set2_labels)\n",
        "    I1=Compute_Impurity(set1_labels,Classes,criterion)\n",
        "    I2=Compute_Impurity(set2_labels,Classes,criterion)\n",
        "\n",
        "    #Gesamt-Reinheit wird für diesem split bei diesem Threshold berechnet\n",
        "    overall_impurity_child_nodes=(N1/N)*I1+(N2/N)*I1\n",
        "          for element in\n",
        "\n",
        "            # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "\n",
        "        if (best_feature==None or best_split_value==None):\n",
        "            self.splittable = False\n",
        "            self.splitting_feature__ = None\n",
        "            self.splitting_feature_Threshold__ = None\n",
        "        else:\n",
        "            self.splitting_feature__ = best_feature\n",
        "            self.splitting_feature_Threshold__ = best_split_value\n",
        "            self.splittable = True\n",
        "\n",
        "    def binary_split(self):\n",
        "        \"\"\"\n",
        "        Binary split of the node using splitting_feature__ and splitting_feature_Threshold__ attributes\n",
        "\n",
        "        Inputs:\n",
        "        - self: Node\n",
        "\n",
        "        Returns:\n",
        "        - Node_True_branch, Node_False_branch: two objects of Class \"BinaryNode\" which contain samples after split\n",
        "\n",
        "        \"\"\"\n",
        "        if self.splittable is False:\n",
        "            raise ValueError (f\"Node{self.ID} is not splittable\")\n",
        "\n",
        "        #####################################################################\n",
        "        # TODO:                                                             #\n",
        "        # split the samples (and correspoding labels) to two parts:         #\n",
        "        #     \"True_samples\" and \"True_samples_labels\"                      #\n",
        "        #     \"False_samples\" and \"False_samples_labels\"                    #\n",
        "        # True means <=   (less than or equal to threshold)                 #\n",
        "        # False means >   (greater thanthreshold)                           #\n",
        "        #####################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "\n",
        "        # let's instantiate two objects from BinaryNode Class for each branch:\n",
        "        Node_True_branch = BinaryNode(samples=True_samples,labels=True_samples_labels,\n",
        "                                      Classes=self.Classes,Impurity_criterion=self.impurity_criterion,\n",
        "                                      parentID=self.ID,Branch =True)\n",
        "\n",
        "        Node_False_branch = BinaryNode(samples=False_samples,labels=False_samples_labels,\n",
        "                                       Classes=self.Classes,Impurity_criterion=self.impurity_criterion,\n",
        "                                       parentID=self.ID,Branch = False)\n",
        "\n",
        "        return Node_True_branch, Node_False_branch\n",
        "\n",
        "\n",
        "    def __count_samples_per_class(self, Classes):\n",
        "        \"\"\"\n",
        "        count the number of Node samples in each class\n",
        "\n",
        "        Inputs:\n",
        "        - self: Node\n",
        "        - Classes: Numpy array of size (K,) containing the labels of classes in the dataset\n",
        "\n",
        "        Returns:\n",
        "        - sets the attribute \"count\" for the Node , where\n",
        "            count[i] is the number of samples with the label Classes[i].\n",
        "\n",
        "        \"\"\"\n",
        "        self.count=np.zeros(Classes.shape[0])\n",
        "        for c in Classes:\n",
        "            self.count[c]=np.count_nonzero(self.labels==c)\n",
        "\n",
        "    def describe(self):\n",
        "        '''\n",
        "        helper function to print the Node information\n",
        "        '''\n",
        "        print(\"---------------------------\")\n",
        "        print(\"Describing Node{}:\".format(self.ID))\n",
        "        print(f'depth ={self.depth}, ID = {self.ID}')\n",
        "        if self.splittable:\n",
        "            print(f\"leaf?: {not self.splittable}, splitting_feature__={self.splitting_feature__}, splitting_threshold: {self.splitting_feature_Threshold__}\")\n",
        "        else:\n",
        "            print(f\"leaf?: {not self.splittable}\")\n",
        "\n",
        "        print(f'samples = {self.num_samples}, counts = {self.count}, proabilities = {self.probs}')\n",
        "        print(f'impurity: {self.impurity_criterion} = {self.impurity:3.5}')\n",
        "        print(f'Class: {self.Class}')#Most_Frequent_samples are from class\n",
        "\n",
        "#bie hier importiert\n",
        "binary_node = BinaryNode(X,y,Classes,'entropy')\n",
        "binary_node.describe()"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "zB7w-dvjQ962"
      },
      "source": [
        "Your result should look like:\n",
        "\n",
        "---------------------------\n",
        "Describing Node[0]:\n",
        "depth =0, ID = [0]\n",
        "leaf?: False, splitting_feature__=0, splitting_threshold: 2.45\n",
        "samples = 150, counts = [50. 50. 50.], proabilities = [0.33333333 0.33333333 0.33333333]\n",
        "impurity: entropy = 1.585\n",
        "Class: 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6CXxq3mQ962"
      },
      "source": [
        "### Binary split at each node (10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWOm05-1Q962"
      },
      "source": [
        "After finding the best split of a node, implement the function *binary_split* in `TUBS_1120019/decision_tree_classifier/Node.py` to split the binary node to 2 child nodes. Then run the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vg-T6KJKQ962"
      },
      "outputs": [],
      "source": [
        "node_true,node_false = binary_node.binary_split()\n",
        "node_true.describe()\n",
        "node_false.describe()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "Xns6dYOiQ963"
      },
      "source": [
        "Your result should look like:\n",
        "\n",
        "---------------------------\n",
        "Describing Node[0, 1]:\n",
        "depth =1, ID = [0, 1]\n",
        "leaf?: True\n",
        "samples = 50, counts = [50.  0.  0.], proabilities = [1. 0. 0.]\n",
        "impurity: entropy = -0.0\n",
        "Class: 0\n",
        "---------------------------\n",
        "Describing Node[0, 0]:\n",
        "depth =1, ID = [0, 0]\n",
        "leaf?: False, splitting_feature__=1, splitting_threshold: 1.75\n",
        "samples = 100, counts = [ 0. 50. 50.], proabilities = [0.  0.5 0.5]\n",
        "impurity: entropy = 1.0\n",
        "Class: 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhmC7fzuQ963"
      },
      "source": [
        "Building block (node) of our Decision Tree classifier is ready.  \n",
        "we provided an implementation of training and prediction of decision tree classifier for you in `TUBS_1120019/decision_tree_classifier/decision_tree.py`  \n",
        "\n",
        "we will:\n",
        "- First split the dataset into train and test set\n",
        "- Use BinaryDecisonTree class and training set to train the classifer\n",
        "- Evaluate the classifier on test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXnF00EtQ963"
      },
      "source": [
        "## Split the data into train and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Twwm0NREQ963"
      },
      "outputs": [],
      "source": [
        "from TUBS_1120019.data_utils import split_into_2_sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = split_into_2_sets(\n",
        "    X, y, first_set_size=0.8, shuffle=True, random_state=seed)\n",
        "\n",
        "# As a sanity check of loading the dataset, we print out the size of the training and test data.\n",
        "print(\"Training data shape: \", X_train.shape, X_train.dtype)\n",
        "print(\"Training labels shape: \", y_train.shape, y_train.dtype)\n",
        "print(\"Test data shape: \", X_test.shape, X_test.dtype)\n",
        "print(\"Test labels shape: \", y_test.shape, y_test.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXs_w28rQ964"
      },
      "outputs": [],
      "source": [
        "from TUBS_1120019.decision_tree_classifier.decision_tree import BinaryDecisonTree\n",
        "\n",
        "\n",
        "DT_clf = BinaryDecisonTree(X_train, y_train, Classes, impurity_criterion=\"entropy\")\n",
        "\n",
        "DT_clf.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJmq4msDQ964"
      },
      "source": [
        "You can print the details of the trained decision tree:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opAibpKJQ965"
      },
      "outputs": [],
      "source": [
        "DT_clf.print_tree()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUZ6m9WeQ966"
      },
      "outputs": [],
      "source": [
        "y_train_pred = DT_clf.predict(X_train)\n",
        "train_accuracy = np.mean(y_train == y_train_pred)\n",
        "print(\"Decision Tree: train set accuracy: %f\" % train_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFkZkmxtQ966"
      },
      "source": [
        "We already now that naive decision trees are prone to overfitting.\n",
        "So, we expect the training accuracy to be \"almost\" 100%  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvay-lPQQ966"
      },
      "source": [
        "## Report the results on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_WiHqOuQ967"
      },
      "outputs": [],
      "source": [
        "y_test_pred = DT_clf.predict(X_test)\n",
        "test_accuracy = np.mean(y_test == y_test_pred)\n",
        "print(\"Decision Tree: test set accuracy: %f\" % test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhTA175-Q967"
      },
      "source": [
        "**Inline Question** (4pnts)\n",
        "- Inspite of expected overfitting (training accuracy~100%), test accuracy is also very high. Do you know why that happens?  \n",
        "<font color='blue'>*Your Explanation*:</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwshHmcZQ968"
      },
      "source": [
        "## Visualize the decision boundary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-p8_N8QQ968"
      },
      "outputs": [],
      "source": [
        "plot_samples_classification(X, y, DT_clf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AE2W5PkQ968"
      },
      "source": [
        "# Check with scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vD2hErjQ969"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree_clf = DecisionTreeClassifier(random_state=42, criterion=\"entropy\")\n",
        "tree_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWlzCaT6Q969"
      },
      "outputs": [],
      "source": [
        "y_test_pred = tree_clf.predict(X_test)\n",
        "test_accuracy = np.mean(y_test == y_test_pred)\n",
        "print(\"Decision Tree: test set accuracy: %f\" % test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svBBBlxzQ96-"
      },
      "outputs": [],
      "source": [
        "plot_samples_classification(X, y, tree_clf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arMQ_U1KQ96-"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import plot_tree\n",
        "\n",
        "plt.figure(figsize=(16, 12))\n",
        "plot_tree(tree_clf)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJ1rOC6EQ96_"
      },
      "source": [
        "# Recursion (30pnts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amzWFPtPQ96_"
      },
      "source": [
        "**Backup your files or push them in your repository and then continue.**\n",
        "\n",
        "we provided an implementation of training and prediction of decision tree classifier for you in `TUBS_1120019/decision_tree_classifier/decision_tree.py`.\n",
        "In our code, prediction is implemented as a recursive function.\n",
        "\n",
        "You task is to write a recursive function for training method.  \n",
        "Rename the non-recursive function (that is already in the file) to training_non_recursive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2p-RuYFOQ97A"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc-autonumbering": true,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}